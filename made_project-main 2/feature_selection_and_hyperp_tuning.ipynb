{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwHxOF_dIDSE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Selection"
      ],
      "metadata": {
        "id": "jq7WiYMDIJwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif"
      ],
      "metadata": {
        "id": "OY_9GX9mILOc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "С указание количества"
      ],
      "metadata": {
        "id": "VRdRLi9hIgP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def select_features(X, y, num_features):\n",
        "    '''\n",
        "    The function uses the SelectKBest class from sklearn to perform \n",
        "    feature selection using the f_classif function, \n",
        "    which computes the ANOVA F-value between the feature and the target. \n",
        "    It then returns the selected features as a new 2D array or matrix.\n",
        "    '''\n",
        "    # Perform feature selection\n",
        "    selector = SelectKBest(f_classif, k=num_features)\n",
        "    selector.fit(X, y)\n",
        "\n",
        "    # Get the selected features\n",
        "    selected_features = selector.get_support(indices=True)\n",
        "\n",
        "    # Return the selected features\n",
        "    return X[:,selected_features], selected_features"
      ],
      "metadata": {
        "id": "2FhTSe3hIMoP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RFE - лучше всего использовать это"
      ],
      "metadata": {
        "id": "VYhaPuW3xVhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def select_features_rfe(X, y, num_features):\n",
        "    # Create a Logistic Regression model\n",
        "    model = LogisticRegression()\n",
        "    # Create an RFE selector\n",
        "    selector = RFE(model, num_features)\n",
        "    # Fit the selector to the data\n",
        "    selector.fit(X, y)\n",
        "    # Get the selected features\n",
        "    features = selector.transform(X)\n",
        "    return features\n"
      ],
      "metadata": {
        "id": "iKXvW1-3xUKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "С указанием персентиля"
      ],
      "metadata": {
        "id": "2a8wrpJaIi5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "\n",
        "def select_features(X, y, percentile):\n",
        "    '''\n",
        "    This function is similar to the previous example, but it uses the\n",
        "     SelectPercentile class from sklearn instead of SelectKBest. \n",
        "     The SelectPercentile class allows you to select a certain percentile \n",
        "     of the highest scoring features, rather than a specific number of features.\n",
        "    '''\n",
        "    # Perform feature selection\n",
        "    selector = SelectPercentile(f_classif, percentile=percentile)\n",
        "    selector.fit(X, y)\n",
        "\n",
        "    # Get the selected features\n",
        "    selected_features = selector.get_support(indices=True)\n",
        "\n",
        "    # Return the selected features\n",
        "    return X[:,selected_features], selected_features\n",
        "\n",
        "# selected_features = select_features(X, y, 20)\n"
      ],
      "metadata": {
        "id": "ONOPi9L1IQGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "На основе фиче импортанс"
      ],
      "metadata": {
        "id": "haBuAqxGI6QX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def select_features(X, y):\n",
        "    # Build a random forest classifier\n",
        "    clf = RandomForestClassifier()\n",
        "\n",
        "    # Perform feature selection using the random forest classifier\n",
        "    selector = SelectFromModel(clf)\n",
        "    selector.fit(X, y)\n",
        "\n",
        "    # Get the selected features\n",
        "    selected_features = selector.get_support(indices=True)\n",
        "\n",
        "    # Return the selected features\n",
        "    return X[:,selected_features], selected_features\n"
      ],
      "metadata": {
        "id": "A0TKZMKJI8Ml"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Q4Lo3OjxSyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M2b3-jLYI-O2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подбор гиперпараметров"
      ],
      "metadata": {
        "id": "7g4cciO5JHex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_lr = {'C': [0.01, 0.1, 1, 10, 100],\n",
        "              'penalty': ['l1', 'l2']}\n",
        "param_grid_brf = {'n_estimators': [50, 100, 150, 200],\n",
        "              'max_depth': [None, 5, 10, 15]}\n",
        "param_grid_xgb = {'max_depth': [3, 5, 7, 9],\n",
        "              'learning_rate': [0.1, 0.3, 0.5, 0.7],\n",
        "              'n_estimators': [50, 100, 150, 200]}\n",
        "param_grid_rusboost = {'n_estimators': [50, 100, 150, 200],\n",
        "              'learning_rate': [0.1, 0.3, 0.5, 0.7],\n",
        "              'max_depth': [3, 5, 7, 9],\n",
        "              'random_state': [42]}\n",
        "\n"
      ],
      "metadata": {
        "id": "YUG8Sz5bKOe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def select_hyperparameters(model, X, y, param_grid):\n",
        "    # Create a grid search object\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=-1, verbose=2)\n",
        "\n",
        "    # Fit the grid search object to the data\n",
        "    grid_search.fit(X, y)\n",
        "\n",
        "    # Return the best hyperparameters\n",
        "    return grid_search.best_params_\n"
      ],
      "metadata": {
        "id": "afbOm-ohJKNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_distributions_lr = {'C': np.logspace(-3, 3, 7),\n",
        "                       'penalty': ['l1', 'l2']}\n",
        "param_distributions_brf = {'n_estimators': np.arange(50, 201, 50),\n",
        "                       'max_depth': [None, 5, 10, 15]}\n",
        "param_distributions_xgb = {'max_depth': np.arange(3, 10, 2),\n",
        "                       'learning_rate': np.linspace(0.1, 1, 5),\n",
        "                       'n_estimators': np.arange(50, 201, 50),\n",
        "                       'random_state': [42]}\n",
        "param_distributions_rusboost = {'n_estimators': np.arange(50, 201, 50),\n",
        "                       'learning_rate': np.linspace(0.1, 1, 5),\n",
        "                       'max_depth': np.arange(3, 10, 2),\n",
        "                       'random_state': [42]}"
      ],
      "metadata": {
        "id": "JJX6h8KzML5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import numpy as np\n",
        "\n",
        "def select_hyperparameters(model, X, y, param_distributions, n_iter):\n",
        "    # Create a random search object\n",
        "    random_search = RandomizedSearchCV(model, param_distributions, n_iter=n_iter, cv=5, n_jobs=-1, verbose=2)\n",
        "\n",
        "    # Fit the random search object to the data\n",
        "    random_search.fit(X, y)\n",
        "\n",
        "    # Return the best hyperparameters\n",
        "    return random_search.best_params_\n"
      ],
      "metadata": {
        "id": "31tYwdkaJuBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rusboost = RUSBoostClassifier()\n",
        "\n",
        "# # Select the best hyperparameters for the RUSBoost model\n",
        "# best_params = select_hyperparameters(rusboost, X, y, param_distributions_rusboost, n_iter=10)"
      ],
      "metadata": {
        "id": "8ugftqP5M5tE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xUV-A-9EM3qQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}